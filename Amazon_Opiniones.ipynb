{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/Amazon_Opiniones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NessjW5cMUX",
    "lang": "es"
   },
   "source": [
    "## Descargar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:06:14.598916Z",
     "start_time": "2019-08-14T17:06:04.653232Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PeIbHaSMvy5J"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "!wget -q -O train_text.p 'https://docs.google.com/uc?export=download&id=1-0WEtyIuvB8pxENu8WJvgYFb8aMc4F8R'\n",
    "!wget -q -O train_label.p 'https://docs.google.com/uc?export=download&id=1-AKY4RWMXDg035vTJQLqUXIjYMw6Ja1t'\n",
    "!wget -q -O test_text.p 'https://docs.google.com/uc?export=download&id=1-4WBoOczIwOpd-Qu5n4dINcor9wC7UUk'\n",
    "\n",
    "train_text = pickle.load(open('train_text.p', 'rb'))\n",
    "train_label = pickle.load(open('train_label.p', 'rb'))\n",
    "test_text = pickle.load(open('test_text.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmX5AQqZUHdr"
   },
   "source": [
    "### -----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7_WoHvWcUhq",
    "lang": "es"
   },
   "source": [
    "## Tu modelo va aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Your model goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:06:17.376107Z",
     "start_time": "2019-08-14T17:06:17.268506Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "51Lh8GgcqjjD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "max_len = 512\n",
    "train_text = [\n",
    "    re.sub(r'([^\\s\\w]|_)+', ' ', _).lower().split() for _ in train_text\n",
    "]\n",
    "train_text = [_[:max_len] + [''] * (max_len - len(_)) for _ in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:07:19.430037Z",
     "start_time": "2019-08-14T17:07:11.358604Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "nTJz7DaGUx1I",
    "outputId": "5e7a29d0-278c-4b7c-e4b6-510bceaea621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 loss = 14.1401609375\n",
      "#2 loss = 11.349340625\n",
      "#3 loss = 11.0936203125\n",
      "#4 loss = 10.284378125\n",
      "#5 loss = 9.76591875\n",
      "#6 loss = 9.1864625\n",
      "#7 loss = 9.093525\n",
      "#8 loss = 8.73450625\n",
      "#9 loss = 8.348775\n",
      "#10 loss = 8.42749375\n",
      "#11 loss = 8.29356875\n",
      "#12 loss = 7.87945\n",
      "#13 loss = 8.062975\n",
      "#14 loss = 8.0707\n",
      "#15 loss = 8.0523625\n",
      "#16 loss = 7.7583625\n",
      "#17 loss = 7.7898875\n",
      "#18 loss = 7.7614375\n",
      "#19 loss = 7.1874625\n",
      "#20 loss = 7.6908625\n",
      "Word2Vec(vocab=9005, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class logger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.loss = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print('#{}'.format(self.epoch), 'loss =',\n",
    "              (model.get_latest_training_loss() - self.loss) /\n",
    "              model.batch_words)\n",
    "        self.epoch += 1\n",
    "        self.loss = model.get_latest_training_loss()\n",
    "\n",
    "\n",
    "embedding_model = gensim.models.Word2Vec(sentences=train_text,\n",
    "                                         size=100,\n",
    "                                         min_count=0,\n",
    "                                         iter=20,\n",
    "                                         compute_loss=True,\n",
    "                                         callbacks=[logger()])\n",
    "print(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:07:19.821215Z",
     "start_time": "2019-08-14T17:07:19.432176Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l1Jf8Ss_e1RX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.concatenate([\n",
    "    np.array([embedding_model.wv.vocab[word].index\n",
    "              for word in _])[np.newaxis, :] for _ in train_text\n",
    "],\n",
    "                         axis=0)\n",
    "y_train = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:07:21.782185Z",
     "start_time": "2019-08-14T17:07:19.822680Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "eknY-xH_U0wo",
    "outputId": "130f9b73-16b3-4eab-849d-8cddf1df3bf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 19:07:20.841528 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0814 19:07:20.852877 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0814 19:07:20.854573 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0814 19:07:20.859352 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0814 19:07:20.860143 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0814 19:07:21.716301 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0814 19:07:21.755107 139720662660928 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0814 19:07:21.767784 139720662660928 deprecation.py:323] From /usr/lib/python3/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 512, 100)          900500    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 508, 256)          128256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 101, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 97, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 19, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,750,677\n",
      "Trainable params: 850,177\n",
      "Non-trainable params: 900,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(input_dim=embedding_model.wv.vectors.shape[0],\n",
    "              output_dim=embedding_model.wv.vectors.shape[1],\n",
    "              input_length=len(X_train[0]),\n",
    "              weights=[embedding_model.wv.vectors],\n",
    "              trainable=False))\n",
    "model.add(Conv1D(256, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(256, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(256, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:07:40.588558Z",
     "start_time": "2019-08-14T17:07:33.263039Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "TyZtgSsxbGbd",
    "outputId": "35cd7076-0532-46cd-8c02-aab2af04285b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4491 samples, validate on 499 samples\n",
      "Epoch 1/100\n",
      "4491/4491 [==============================] - 3s 614us/step - loss: 0.5837 - acc: 0.7747 - val_loss: 0.4430 - val_acc: 0.8257\n",
      "Epoch 2/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.4096 - acc: 0.8521 - val_loss: 0.4298 - val_acc: 0.8257\n",
      "Epoch 3/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.3916 - acc: 0.8524 - val_loss: 0.4092 - val_acc: 0.8257\n",
      "Epoch 4/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.3556 - acc: 0.8537 - val_loss: 0.3657 - val_acc: 0.8257\n",
      "Epoch 5/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.3212 - acc: 0.8626 - val_loss: 0.3366 - val_acc: 0.8397\n",
      "Epoch 6/100\n",
      "4491/4491 [==============================] - 0s 80us/step - loss: 0.2915 - acc: 0.8733 - val_loss: 0.3236 - val_acc: 0.8397\n",
      "Epoch 7/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.2721 - acc: 0.8789 - val_loss: 0.2913 - val_acc: 0.8697\n",
      "Epoch 8/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.2461 - acc: 0.8931 - val_loss: 0.2904 - val_acc: 0.8758\n",
      "Epoch 9/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.2121 - acc: 0.9120 - val_loss: 0.2862 - val_acc: 0.8657\n",
      "Epoch 10/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.1755 - acc: 0.9294 - val_loss: 0.3578 - val_acc: 0.8517\n",
      "Epoch 11/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.1552 - acc: 0.9341 - val_loss: 0.2925 - val_acc: 0.8697\n",
      "Epoch 12/100\n",
      "4491/4491 [==============================] - 0s 79us/step - loss: 0.1055 - acc: 0.9662 - val_loss: 0.3127 - val_acc: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1325e860b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_weights('AmazonModel.h5')\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min'),\n",
    "    ModelCheckpoint('AmazonModel.h5',\n",
    "                    save_best_only=True,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min')\n",
    "]\n",
    "# class_weight {'0' : ... , '1' : ... }\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_split=0.1,\n",
    "          epochs=100,\n",
    "          batch_size=512,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:07:46.151079Z",
     "start_time": "2019-08-14T17:07:45.489927Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oZTjeeeChzNU"
   },
   "outputs": [],
   "source": [
    "test_text = [\n",
    "    re.sub(r'([^\\s\\w]|_)+', ' ', _).lower().split() for _ in test_text\n",
    "]\n",
    "test_text = [_[:max_len] + [''] * (max_len - len(_)) for _ in test_text]\n",
    "\n",
    "X_test = np.concatenate([\n",
    "    np.array([\n",
    "        embedding_model.wv.vocab.get(word, embedding_model.wv.vocab['']).index\n",
    "        for word in _\n",
    "    ])[np.newaxis, :] for _ in test_text\n",
    "],\n",
    "                        axis=0)\n",
    "\n",
    "model.load_weights('AmazonModel.h5')\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMzIbFVmi1DB"
   },
   "source": [
    "### -----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----8<-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9CSVWgkc3bl",
    "lang": "es"
   },
   "source": [
    "## Tus predicciones deberían tener este formato\n",
    "\n",
    "- Un numpy array de 2736 probabilidades de que la etiqueta sea '1' por cada uno de las muestras de test_text\n",
    "- ¡El que menor log_loss (binary_cross_entropy) consigue ganará un premio y entrará en el salón de la fama!\n",
    "- Manda el fichero pickleado a teticio@gmail.com para obtener tu puntuación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Your predictions should have this format\n",
    "\n",
    "- A numpy array of 2736 probabilities that the label is '1' for each of the test samples _text\n",
    "- The one with the smallest log_ loss (binary _cross_ entropy) will win a prize and enter the hall of fame!\n",
    "- Send the pickled file to teticio@gmail.com to get your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:08:01.596905Z",
     "start_time": "2019-08-14T17:08:01.589828Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "RrC8Uht7hqzH",
    "outputId": "f2f3338a-b97b-42aa-edbd-2878d6799e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85790634],\n",
       "       [0.8618407 ],\n",
       "       [0.20527825],\n",
       "       ...,\n",
       "       [0.66388637],\n",
       "       [0.5482094 ],\n",
       "       [0.9837644 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(test_pred, open('test_pred.p', 'wb'))\n",
    "\n",
    "try:\n",
    "    from google.colab import files  # estamos en colab?\n",
    "    files.download('test_pred.p')  # descargar al ordenador local\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(len(test_pred))\n",
    "test_pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Amazon Opiniones.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
